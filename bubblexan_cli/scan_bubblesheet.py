#!/usr/bin/env python3
"""
Bubble Sheet Scanner

Processes scanned images of bubble sheets generated by generate_bubblesheet.py.
Uses the layout JSON guide rail to map bubble locations and produces a CSV with
decoded student IDs and selected answers.
"""

from __future__ import annotations

import argparse
import csv
import json
import math
import textwrap
import zipfile
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, Iterator, List, Optional, Sequence, Tuple

import cv2
import numpy as np

IMAGE_EXTENSIONS = {".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"}


@dataclass
class BubbleDef:
    label: str
    x: float
    y: float
    radius: float


@dataclass
class QuestionDef:
    number: int
    bubbles: List[BubbleDef]


@dataclass
class StudentIDColumn:
    digit_index: int
    bubbles: List[BubbleDef]


@dataclass
class LayoutGuide:
    width: float
    height: float
    questions: List[QuestionDef]
    student_id_columns: List[StudentIDColumn]
    alignment_markers: List[Dict[str, float]]
    metadata: Dict[str, float]


@dataclass
class ScanResult:
    source_name: str
    student_id: str
    answers: Dict[int, str]
    warnings: List[str]


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Scan bubble sheet images and export selections to CSV.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--image", help="Path to a single scanned image.")
    group.add_argument("--folder", help="Path to a folder or .zip containing scanned images.")
    parser.add_argument("--json", required=True, help="Path to the layout JSON generated by the Bubble Sheet Generator.")
    parser.add_argument("--output", required=True, help="Destination CSV filename or prefix.")
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.35,
        help="Absolute fill ratio threshold (0-1) to accept a bubble without fallback.",
    )
    parser.add_argument(
        "--relative-threshold",
        type=float,
        default=0.6,
        help="Fallback ratio of the darkest bubble intensity for selecting answers when no bubble meets the absolute threshold.",
    )
    parser.add_argument(
        "--log",
        help="Optional log file. Defaults to <output>.log when omitted.",
    )
    parser.add_argument(
        "--output-dir",
        default="output",
        help="Directory for generated CSV/log files when using relative output paths.",
    )
    return parser.parse_args()


def load_layout(json_path: Path) -> LayoutGuide:
    with json_path.open("r", encoding="utf-8") as fp:
        data = json.load(fp)

    questions = [
        QuestionDef(
            number=item["number"],
            bubbles=[BubbleDef(label=opt["option"], x=opt["x"], y=opt["y"], radius=opt["radius"]) for opt in item["bubbles"]],
        )
        for item in data["questions"]
    ]
    student_columns = [
        StudentIDColumn(
            digit_index=col.get("digit_index") or col.get("digit"),
            bubbles=[BubbleDef(label=b["value"], x=b["x"], y=b["y"], radius=b["radius"]) for b in col["bubbles"]],
        )
        for col in data["student_id"]
    ]
    markers: List[Dict[str, float]] = []
    for marker in data.get("alignment_markers", []):
        markers.append(
            {
                "x": float(marker["x"]),
                "y": float(marker["y"]),
                "size": float(marker.get("size", 0)),
                "type": marker.get("type", "square"),
            }
        )

    dimensions = data["dimensions"]
    metadata = data.get("metadata", {})
    return LayoutGuide(
        width=float(dimensions["width"]),
        height=float(dimensions["height"]),
        questions=questions,
        student_id_columns=student_columns,
        alignment_markers=markers,
        metadata=metadata,
    )


def iter_image_sources(image_path: Optional[Path], folder_path: Optional[Path]) -> Iterator[Tuple[str, np.ndarray]]:
    if image_path:
        image = cv2.imread(str(image_path))
        if image is None:
            raise FileNotFoundError(f"Unable to read image: {image_path}")
        yield (image_path.name, image)
        return

    assert folder_path is not None
    if folder_path.is_file() and folder_path.suffix.lower() == ".zip":
        with zipfile.ZipFile(folder_path) as zf:
            for info in zf.infolist():
                if info.is_dir():
                    continue
                if not is_image_file(info.filename):
                    continue
                data = zf.read(info.filename)
                np_data = np.frombuffer(data, dtype=np.uint8)
                image = cv2.imdecode(np_data, cv2.IMREAD_COLOR)
                if image is None:
                    continue
                yield (info.filename, image)
    else:
        if not folder_path.exists():
            raise FileNotFoundError(f"Folder not found: {folder_path}")
        for file_path in sorted(folder_path.rglob("*")):
            if not file_path.is_file() or not is_image_file(file_path.name):
                continue
            image = cv2.imread(str(file_path))
            if image is None:
                continue
            rel_name = str(file_path.relative_to(folder_path))
            yield (rel_name, image)


def is_image_file(name: str) -> bool:
    return Path(name).suffix.lower() in IMAGE_EXTENSIONS


def to_top_left_coords(x: float, y: float, layout_height: float) -> Tuple[float, float]:
    return float(x), float(layout_height - y)


def order_points_clockwise(points: Sequence[Tuple[float, float]]) -> List[Tuple[float, float]]:
    pts = np.array(points, dtype=np.float32)
    rect = np.zeros((4, 2), dtype=np.float32)
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]  # top-left
    rect[2] = pts[np.argmax(s)]  # bottom-right
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]  # top-right
    rect[3] = pts[np.argmax(diff)]  # bottom-left
    return rect.tolist()


def detect_alignment_markers(gray: np.ndarray, max_markers: int = 4) -> List[Tuple[float, float]]:
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    candidates: List[Tuple[float, float, float]] = []
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < 200:
            continue
        perimeter = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)
        if len(approx) != 4:
            continue
        rect = cv2.minAreaRect(contour)
        width, height = rect[1]
        if min(width, height) == 0:
            continue
        aspect_ratio = max(width, height) / min(width, height)
        if aspect_ratio > 1.3:
            continue
        moments = cv2.moments(contour)
        if moments["m00"] == 0:
            continue
        c_x = moments["m10"] / moments["m00"]
        c_y = moments["m01"] / moments["m00"]
        candidates.append((area, c_x, c_y))
    candidates.sort(reverse=True, key=lambda item: item[0])
    return [(c[1], c[2]) for c in candidates[:max_markers]]


def detect_guided_alignment_markers(
    gray: np.ndarray,
    layout: LayoutGuide,
    window_radius: int,
    max_markers: int = 4,
) -> List[Tuple[float, float]]:
    image_h, image_w = gray.shape[:2]
    scale_x = image_w / layout.width
    scale_y = image_h / layout.height
    guided: List[Tuple[float, float, float]] = []
    for marker in layout.alignment_markers[:max_markers]:
        size = marker.get("size", 0.0)
        center_x = marker["x"] + size / 2.0
        center_y = marker["y"] + size / 2.0
        approx_x = center_x * scale_x
        approx_y = (layout.height - center_y) * scale_y
        x1 = max(0, int(round(approx_x - window_radius)))
        y1 = max(0, int(round(approx_y - window_radius)))
        x2 = min(image_w, int(round(approx_x + window_radius)))
        y2 = min(image_h, int(round(approx_y + window_radius)))
        if x2 <= x1 or y2 <= y1:
            continue
        roi = gray[y1:y2, x1:x2]
        blur = cv2.GaussianBlur(roi, (5, 5), 0)
        _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        best_area = 0.0
        best_center: Optional[Tuple[float, float]] = None
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 50:
                continue
            M = cv2.moments(contour)
            if M["m00"] == 0:
                continue
            cx = M["m10"] / M["m00"] + x1
            cy = M["m01"] / M["m00"] + y1
            if area > best_area:
                best_area = area
                best_center = (cx, cy)
        if best_center is not None:
            guided.append((best_area, best_center[0], best_center[1]))
    guided.sort(reverse=True, key=lambda item: item[0])
    return [(c[1], c[2]) for c in guided[:max_markers]]


def detect_page_corners(gray: np.ndarray) -> Optional[List[Tuple[float, float]]]:
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edged = cv2.Canny(blur, 50, 150)
    edged = cv2.dilate(edged, None, iterations=2)
    edged = cv2.erode(edged, None, iterations=1)
    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < 1000:
            continue
        peri = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
        if len(approx) == 4:
            return [(float(pt[0][0]), float(pt[0][1])) for pt in approx]
    return None


def build_layout_to_image_transform(
    layout: LayoutGuide, gray_image: np.ndarray
) -> Tuple[np.ndarray, List[str]]:
    warnings: List[str] = []
    image_h, image_w = gray_image.shape[:2]
    layout_markers = layout.alignment_markers[:4]
    detected_markers = detect_alignment_markers(gray_image) if layout_markers else []
    guided_used = False
    if len(layout_markers) == 4 and len(detected_markers) < 4:
        window = int(max(image_w, image_h) * 0.12)
        guided = detect_guided_alignment_markers(gray_image, layout, window)
        if len(guided) == 4:
            detected_markers = guided
            guided_used = True
    use_alignment = False
    matrix: Optional[np.ndarray] = None
    page_corners: Optional[List[Tuple[float, float]]] = None

    if len(layout_markers) == 4 and len(detected_markers) == 4:
        layout_points = []
        for marker in layout_markers:
            size = marker.get("size", 0.0)
            center_x = marker["x"] + size / 2.0
            center_y = marker["y"] + size / 2.0
            layout_points.append(to_top_left_coords(center_x, center_y, layout.height))
        layout_points_ordered = order_points_clockwise(layout_points)
        detected_ordered = order_points_clockwise(detected_markers)
        detected_arr = np.array(detected_ordered, dtype=np.float32)
        span_w = float(detected_arr[:, 0].max() - detected_arr[:, 0].min())
        span_h = float(detected_arr[:, 1].max() - detected_arr[:, 1].min())
        min_span_w = image_w * 0.25
        min_span_h = image_h * 0.25
        if span_w >= min_span_w and span_h >= min_span_h:
            matrix = cv2.getPerspectiveTransform(
                np.array(layout_points_ordered, dtype=np.float32),
                detected_arr,
            )
            use_alignment = True
            if guided_used:
                warnings.append("Alignment markers recovered via guided search.")
        else:
            warnings.append("Detected markers cover too small an area; using proportional mapping instead.")

    if not use_alignment or matrix is None:
        page_corners = detect_page_corners(gray_image)
        if page_corners is not None:
            page_ordered = order_points_clockwise(page_corners)

            layout_page_corners = order_points_clockwise(
                [
                    to_top_left_coords(0, layout.height, layout.height),
                    to_top_left_coords(layout.width, layout.height, layout.height),
                    to_top_left_coords(layout.width, 0, layout.height),
                    to_top_left_coords(0, 0, layout.height),
                ]
            )

            use_border_frame = False
            border_offset = float(layout.metadata.get("margin", 0.0)) / 2.0
            if border_offset > 0:
                image_h, image_w = gray_image.shape[:2]
                xs = [pt[0] for pt in page_ordered]
                ys = [pt[1] for pt in page_ordered]
                inset_left = max(0.0, min(xs))
                inset_right = max(0.0, image_w - max(xs))
                inset_top = max(0.0, min(ys))
                inset_bottom = max(0.0, image_h - max(ys))
                sum_inset_x = inset_left + inset_right
                sum_inset_y = inset_top + inset_bottom
                sum_ratio_x = sum_inset_x / max(1.0, image_w)
                sum_ratio_y = sum_inset_y / max(1.0, image_h)
                expected_sum_ratio_x = (2.0 * border_offset) / layout.width
                expected_sum_ratio_y = (2.0 * border_offset) / layout.height
                tol_x = max(0.02, expected_sum_ratio_x * 0.6)
                tol_y = max(0.02, expected_sum_ratio_y * 0.6)
                close_x = abs(sum_ratio_x - expected_sum_ratio_x) <= tol_x
                close_y = abs(sum_ratio_y - expected_sum_ratio_y) <= tol_y
                if close_x and close_y:
                    use_border_frame = True

            if use_border_frame:
                layout_border_corners = order_points_clockwise(
                    [
                        to_top_left_coords(border_offset, layout.height - border_offset, layout.height),
                        to_top_left_coords(layout.width - border_offset, layout.height - border_offset, layout.height),
                        to_top_left_coords(layout.width - border_offset, border_offset, layout.height),
                        to_top_left_coords(border_offset, border_offset, layout.height),
                    ]
                )
                chosen_layout = layout_border_corners
                warnings.append("Detected inner border frame for alignment.")
            else:
                chosen_layout = layout_page_corners
                warnings.append("Using page border for alignment.")

            matrix = cv2.getPerspectiveTransform(
                np.array(chosen_layout, dtype=np.float32),
                np.array(page_ordered, dtype=np.float32),
            )
            use_alignment = True

    if not use_alignment or matrix is None:
        if len(layout_markers) < 4 and page_corners is None:
            warnings.append("Insufficient layout markers; using proportional mapping.")
        elif len(detected_markers) < 4 and page_corners is None:
            warnings.append("Failed to detect alignment markers; using proportional mapping.")
        scale_x = image_w / layout.width
        scale_y = image_h / layout.height
        matrix = np.array(
            [
                [scale_x, 0, 0],
                [0, scale_y, 0],
                [0, 0, 1],
            ],
            dtype=np.float32,
        )
    return matrix, warnings


def transform_points(
    matrix: np.ndarray, layout_height: float, points: Sequence[Tuple[float, float]]
) -> np.ndarray:
    layout_coords = np.array(
        [[[x, layout_height - y]] for (x, y) in points],
        dtype=np.float32,
    )
    transformed = cv2.perspectiveTransform(layout_coords, matrix)
    return transformed.reshape(-1, 2)


def measure_bubble_fill(gray: np.ndarray, center: Tuple[float, float], radius: float) -> float:
    h, w = gray.shape[:2]
    mask = np.zeros((h, w), dtype=np.uint8)
    c_x = int(round(center[0]))
    c_y = int(round(center[1]))
    r = max(1, int(round(radius)))
    if c_x + r < 0 or c_x - r > w or c_y + r < 0 or c_y - r > h:
        return 0.0
    cv2.circle(mask, (c_x, c_y), r, 255, -1)
    pixels = gray[mask == 255]
    if pixels.size == 0:
        return 0.0
    return 1.0 - float(pixels.mean()) / 255.0


def estimate_pixel_radius(
    matrix: np.ndarray, layout_height: float, bubble: BubbleDef
) -> float:
    center = transform_points(matrix, layout_height, [(bubble.x, bubble.y)])[0]
    sample_points = [
        (bubble.x + bubble.radius, bubble.y),
        (bubble.x, bubble.y + bubble.radius),
    ]
    transformed = transform_points(matrix, layout_height, sample_points)
    radii = [np.linalg.norm(transformed[i] - center) for i in range(len(transformed))]
    avg_radius = float(np.mean(radii)) if radii else bubble.radius
    return max(1.0, avg_radius)


def scan_student_id(
    gray: np.ndarray,
    layout: LayoutGuide,
    matrix: np.ndarray,
    threshold: float,
    relative_threshold: float,
    min_darkness: float = 0.08,
) -> Tuple[str, List[str]]:
    warnings: List[str] = []
    digits: List[str] = []
    for column in sorted(layout.student_id_columns, key=lambda c: c.digit_index):
        column_scores: List[Tuple[str, float]] = []
        for bubble in column.bubbles:
            center = transform_points(matrix, layout.height, [(bubble.x, bubble.y)])[0]
            radius = estimate_pixel_radius(matrix, layout.height, bubble)
            score = measure_bubble_fill(gray, center, radius)
            column_scores.append((bubble.label, score))
        hits = [label for (label, score) in column_scores if score >= threshold]
        if len(hits) == 1:
            digits.append(hits[0])
            continue

        best_label, best_score = max(column_scores, key=lambda item: item[1])
        rival_score = sorted([score for _, score in column_scores], reverse=True)[1] if len(column_scores) > 1 else 0.0

        if best_score < min_darkness:
            warnings.append(
                f"Digit {column.digit_index}: no bubble above threshold and best mark too light (best {best_label}={best_score:.2f})."
            )
            digits.append("?")
            continue

        if rival_score >= best_score * relative_threshold:
            warnings.append(
                f"Digit {column.digit_index}: ambiguous fill ({best_label}={best_score:.2f}, next={rival_score:.2f})."
            )
            digits.append("?")
            continue

        digits.append(best_label)
    student_id = "".join(digits)
    if "?" in student_id or not student_id:
        warnings.append("Student ID unresolved.")
        student_id = "ERROR"
    return student_id, warnings


def scan_answers(
    gray: np.ndarray,
    layout: LayoutGuide,
    matrix: np.ndarray,
    threshold: float,
    relative_threshold: float,
    min_darkness: float = 0.08,
) -> Tuple[Dict[int, str], List[str]]:
    answers: Dict[int, str] = {}
    warnings: List[str] = []
    for question in layout.questions:
        option_scores: List[Tuple[str, float]] = []
        for bubble in question.bubbles:
            center = transform_points(matrix, layout.height, [(bubble.x, bubble.y)])[0]
            radius = estimate_pixel_radius(matrix, layout.height, bubble)
            score = measure_bubble_fill(gray, center, radius)
            option_scores.append((bubble.label, score))
        selections = [label for (label, score) in option_scores if score >= threshold]
        if selections:
            answers[question.number] = ",".join(sorted(selections))
            continue

        best_label, best_score = max(option_scores, key=lambda item: item[1])
        if best_score < min_darkness:
            warnings.append(
                f"Question {question.number}: no selection above threshold and best mark too light "
                f"(best {best_label}={best_score:.2f})."
            )
            answers[question.number] = ""
            continue

        cutoff = max(threshold * 0.5, best_score * relative_threshold)
        fallback = [label for (label, score) in option_scores if score >= cutoff]
        if not fallback:
            fallback = [best_label]

        answers[question.number] = ",".join(sorted(fallback))
        warnings.append(
            f"Question {question.number}: using relative threshold fallback (best {best_label}={best_score:.2f})."
        )
    return answers, warnings


def scan_image(
    source_name: str,
    image: np.ndarray,
    layout: LayoutGuide,
    threshold: float,
    relative_threshold: float,
) -> ScanResult:
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    matrix, transform_warnings = build_layout_to_image_transform(layout, gray)

    student_id, id_warnings = scan_student_id(gray, layout, matrix, threshold, relative_threshold)
    answers, answer_warnings = scan_answers(gray, layout, matrix, threshold, relative_threshold)

    warnings = [f"{source_name}: {msg}" for msg in (transform_warnings + id_warnings + answer_warnings)]
    return ScanResult(source_name=source_name, student_id=student_id, answers=answers, warnings=warnings)


def write_csv(output_path: Path, question_numbers: List[int], results: List[ScanResult]) -> None:
    output_path.parent.mkdir(parents=True, exist_ok=True)
    headers = ["Student_ID"] + [f"Q{num}" for num in question_numbers]
    with output_path.open("w", newline="", encoding="utf-8") as fp:
        writer = csv.writer(fp)
        writer.writerow(headers)
        for result in results:
            row = [result.student_id]
            for q_num in question_numbers:
                row.append(result.answers.get(q_num, ""))
            writer.writerow(row)


def write_log(log_path: Path, entries: List[str]) -> None:
    if not entries:
        return
    log_path.parent.mkdir(parents=True, exist_ok=True)
    with log_path.open("w", encoding="utf-8") as fp:
        for entry in entries:
            fp.write(entry + "\n")


def resolve_output_paths(output_arg: str, log_arg: Optional[str], output_dir: Path) -> Tuple[Path, Path]:
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = Path(output_arg)
    if not output_path.is_absolute():
        output_path = output_dir / output_path
    if not output_path.suffix:
        output_path = output_path.with_suffix(".csv")

    if log_arg:
        log_path = Path(log_arg)
        if not log_path.is_absolute():
            log_path = output_dir / log_path
    else:
        log_path = output_path.with_suffix(".log")
    return output_path, log_path


def main() -> None:
    args = parse_args()
    json_path = Path(args.json)
    if not json_path.exists():
        raise FileNotFoundError(f"Layout JSON not found: {json_path}")

    layout = load_layout(json_path)
    output_dir = Path(args.output_dir)
    output_path, log_path = resolve_output_paths(args.output, args.log, output_dir)

    threshold = args.threshold
    relative_threshold = args.relative_threshold
    if not (0.0 < threshold <= 1.0):
        raise ValueError("threshold must be between 0 and 1.")

    image_path = Path(args.image) if args.image else None
    folder_path = Path(args.folder) if args.folder else None

    results: List[ScanResult] = []
    log_entries: List[str] = []

    for name, image in iter_image_sources(image_path, folder_path):
        try:
            result = scan_image(name, image, layout, threshold, relative_threshold)
        except Exception as exc:  # noqa: BLE001
            log_entries.append(f"{name}: ERROR processing image ({exc}).")
            answers = {q.number: "" for q in layout.questions}
            results.append(ScanResult(source_name=name, student_id="ERROR", answers=answers, warnings=[]))
            continue
        results.append(result)
        log_entries.extend(result.warnings)

    if not results:
        raise RuntimeError("No images were processed. Please verify the provided inputs.")

    question_numbers = sorted({q.number for q in layout.questions})
    write_csv(output_path, question_numbers, results)
    write_log(log_path, log_entries)
    print(f"Created {output_path}")
    if log_entries:
        print(f"Processing warnings logged to {log_path}")


if __name__ == "__main__":
    main()
